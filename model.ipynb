{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "98e0e3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Training libs\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import IsolationForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04d0188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature groups\n",
    "anomaly_detection_input_features = [\n",
    "    # Non-feature columns\n",
    "    \"transaction_id\",             # Unique identifier for the transaction (dropped in training)\n",
    "    \"date\",                       # (String) Transaction date (YYYY-MM-DD)\n",
    "\n",
    "    # Feature columns\n",
    "    \"amount\",                     # (Float) Transaction amount\n",
    "    \"transaction_type\",           # (String) Credit vs Debit (OHEd)\n",
    "    \"transaction_duration_secs\",  # (Integer) Time in seconds from initiation to settlement\n",
    "    \"is_recurring\",               # (Boolean) Recurring (True) vs one-off (False)\n",
    "    \"location\",                   # (String) City or ZIP code of transaction location (OHEd)\n",
    "    \"device_id\",                  # (String) Unique identifier for the device used (OHEd)\n",
    "    \"merchant_id\",                # (String) Name of the merchant (OHEd)\n",
    "    \"channel\",                    # (String) Channel used for transaction (OHEd)\n",
    "    \"day_of_week\",                # (Integer) Day of week (0=Mon ... 6=Sun)\"\n",
    "    \"hour_of_day\",                # (Integer) Hour of day (0-23)\n",
    "    \"is_holiday\",                 # (Boolean) True if tx on Saturday or Sunday\n",
    "    \"amount_percentile\",          # (Float) Percentile rank in user’s historical amounts\n",
    "    \"time_since_last_tx_secs\",    # (Float) Seconds since previous transaction\n",
    "    \"rolling_mean_3mo_amount\",    # (Float) 3-month trailing mean transaction amount\n",
    "    \"rolling_std_3mo_amount\",     # (Float) 3-month trailing std deviation of amounts\n",
    "\n",
    "    # Other derived features\n",
    "    \"is_weekend\",                # (Boolean) True if transaction occurred on a weekend\n",
    "    \"customer_age\",               # (Integer) Age of customer in years\n",
    "\n",
    "    # Features that decreased metrics\n",
    "    # \"is_new_merchant\",            # (Boolean) True if merchant is new to the customer\n",
    "    # \"is_new_device\",               # (Boolean) True if device is new to the customer\n",
    "]\n",
    "\n",
    "anomaly_detection_output_features = [\n",
    "    # Output features\n",
    "    \"is_anomaly\", # (Boolean): True if the transaction is an anomaly (this is the target)\n",
    "    \"is_anomaly_result\", # (Boolean): Result of the anomaly detection, True if an anomaly\n",
    "    \"anomaly_confidence\", # (Float): Model’s confidence (0–1) in that flag\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "7842dd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset with date parsing\n",
    "df = pd.read_csv(\"assets/chatgpt_data/example_transactions_with_anomalies_o3_with_derived.csv\", parse_dates=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "4887835c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess features (since this data was generated by gpt, we can assume it is clean)\n",
    "def preprocess(v_df: pd.DataFrame) -> None:\n",
    "    #* Sort Data\n",
    "    v_df = v_df.sort_values([\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "bc238e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Cleanup\n",
    "preprocess(df)\n",
    "\n",
    "final_features = [c for c in anomaly_detection_input_features if c in df.columns]\n",
    "df = df[final_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "67f3e2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encode categorical data\n",
    "def encode(v_df, cols_to_encode):\n",
    "    # One-hot encode categorical columns and join into v_df\n",
    "    for col in cols_to_encode:\n",
    "        ohe = OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\")\n",
    "        loc_mat = ohe.fit_transform(v_df[[col]])\n",
    "        loc_cols = [f\"{col}_{c}\" for c in ohe.categories_[0]]\n",
    "        df_loc = pd.DataFrame(loc_mat, columns=loc_cols, index=v_df.index)\n",
    "\n",
    "        # drop the original column and join the new columns\n",
    "        v_df = v_df.drop(columns=[col])\n",
    "        v_df = pd.concat([v_df, df_loc], axis=1)\n",
    "    \n",
    "    return v_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "5e691194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical features to numerical\n",
    "# Drop non-features\n",
    "cols_to_drop = [\"transaction_id\", \"date\"]\n",
    "df = df.drop(columns=cols_to_drop)\n",
    "\n",
    "# One hot encoding for categorical features\n",
    "df = encode(df, [\"merchant_id\", \"location\", \"device_id\", \"channel\"])\n",
    "\n",
    "# Other categorical columns\n",
    "# Convert any boolean columns to 0/1\n",
    "bool_cols = df.select_dtypes(include=\"bool\").columns\n",
    "for c in bool_cols:\n",
    "    df[c] = df[c].astype(int)\n",
    "\n",
    "# Convert credit/debit to binary\n",
    "df['transaction_type'] = df['transaction_type'].map({\n",
    "    'debit': 0,\n",
    "    'credit': 1,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "552f27b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling and Training\n",
    "# Prepare numeric matrix and scale\n",
    "X = df.astype(float)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Train IsolationForest\n",
    "iso = IsolationForest(\n",
    "    n_estimators=500,\n",
    "    max_samples=1.0,      \n",
    "    max_features=1.0,\n",
    "    bootstrap=True,\n",
    "    contamination=0.01,\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    verbose=0,\n",
    ")\n",
    "iso.fit(X_scaled)\n",
    "\n",
    "# Predict & score\n",
    "labels     = iso.predict(X_scaled)         # 1 = normal, -1 = anomaly\n",
    "raw_scores = iso.score_samples(X_scaled)   # higher = more normal\n",
    "\n",
    "df[\"is_anomaly_result\"] = (labels == -1).astype(int)  # 1 = anomaly, 0 = normal\n",
    "\n",
    "inv = -raw_scores\n",
    "df[\"anomaly_confidence\"] = (inv - inv.min()) / (inv.max() - inv.min())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "ebbe7b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9984\n",
      "Precision: 0.9038\n",
      "Recall:    0.9400\n",
      "F1 Score:  0.9216\n",
      "ROC AUC:   0.9994\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# 1. Load & preprocess\n",
    "df_eval = pd.read_csv(\"assets/chatgpt_data/example_transactions_with_anomalies_o3.csv\",\n",
    "                      parse_dates=[\"date\"])\n",
    "preprocess(df_eval)\n",
    "\n",
    "# 2. Extract true labels and drop non-features\n",
    "y_true = df_eval[\"is_anomaly\"].astype(int)\n",
    "cols_to_drop = [\"transaction_id\", \"date\", \"is_anomaly\"]\n",
    "df_eval_model = df_eval.drop(columns=cols_to_drop)\n",
    "\n",
    "# 3. One-hot encode & boolean/map columns exactly as training\n",
    "df_eval_model = encode(df_eval_model, [\"merchant_id\",\"location\",\"device_id\",\"channel\"])\n",
    "for c in df_eval_model.select_dtypes(include=\"bool\").columns:\n",
    "    df_eval_model[c] = df_eval_model[c].astype(int)\n",
    "df_eval_model[\"transaction_type\"] = df_eval_model[\"transaction_type\"].map({\"debit\":0,\"credit\":1})\n",
    "\n",
    "# 4. Align columns with training X\n",
    "train_cols = X.columns\n",
    "for c in train_cols:\n",
    "    if c not in df_eval_model.columns:\n",
    "        df_eval_model[c] = 0\n",
    "df_eval_model = df_eval_model[train_cols]\n",
    "\n",
    "# 5. Scale, predict & score\n",
    "X_eval_scaled = scaler.transform(df_eval_model.astype(float))\n",
    "labels_eval    = iso.predict(X_eval_scaled)          # 1=normal, -1=anomaly\n",
    "y_pred         = (labels_eval == -1).astype(int)\n",
    "scores_eval    = -iso.score_samples(X_eval_scaled)   # higher = more anomalous\n",
    "\n",
    "# 6. Print metrics\n",
    "print(f\"Accuracy:  {accuracy_score(y_true, y_pred):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_true, y_pred, zero_division=0):.4f}\")\n",
    "print(f\"Recall:    {recall_score(y_true, y_pred, zero_division=0):.4f}\")\n",
    "print(f\"F1 Score:  {f1_score(y_true, y_pred, zero_division=0):.4f}\")\n",
    "if len(np.unique(y_true))>1:\n",
    "    print(f\"ROC AUC:   {roc_auc_score(y_true, scores_eval):.4f}\")\n",
    "else:\n",
    "    print(\"ROC AUC:   not defined (single class in true labels)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "acm-industry-pwc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
